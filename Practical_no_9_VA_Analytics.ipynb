{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Object Detection in videos: Detect objects in video sequences using YOLO"
      ],
      "metadata": {
        "id": "dP3yQxaNRBRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZnPNb8ZQyQU"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision opencv-python yolov5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Detection in Video with YOLOv5\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from yolov5 import YOLOv5\n",
        "# Import the cv2_imshow function from google.colab.patches\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load YOLOv5 model (e.g., yolov5s.pt for a small, fast model)\n",
        "model_path = 'yolov5s.pt'  # Download from YOLOv5 repo if needed\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Initialize YOLO model\n",
        "yolo_model = YOLOv5(model_path, device)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture('/content/5538137-hd_1920_1080_25fps.mp4')\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Perform object detection\n",
        "    results = yolo_model.predict(frame)\n",
        "\n",
        "    # Loop over detected objects and draw bounding boxes\n",
        "    for *xyxy, conf, cls in results.pred[0]:  # x1, y1, x2, y2, confidence, class\n",
        "        # Access class names from results.names instead of yolo_model.names\n",
        "        label = results.names[int(cls)]\n",
        "        confidence = f\"{conf:.2f}\"\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)\n",
        "\n",
        "        # Put label and confidence on box\n",
        "        cv2.putText(frame, f\"{label} {confidence}\", (int(xyxy[0]), int(xyxy[1]) - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the frame with detections using cv2_imshow instead of cv2.imshow\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "bGX6JQscQ82Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution logic:\n",
        "\n",
        "Here's a breakdown of each step:\n",
        "\n",
        "### Step-by-Step Explanation\n",
        "\n",
        "1. **Import Required Libraries**:\n",
        "   - `cv2`: OpenCV library for video processing.\n",
        "   - `torch`: PyTorch library to leverage CUDA if available.\n",
        "   - `numpy`: Used for numerical operations, though not directly in this code.\n",
        "   - `YOLOv5`: The YOLOv5 model for object detection.\n",
        "   - `cv2_imshow`: Colabâ€™s specific function to display images in notebooks.\n",
        "\n",
        "2. **Model Path and Device Setup**:\n",
        "   - `model_path`: Specifies the path to the YOLOv5 model file (`yolov5s.pt`).\n",
        "   - `device`: Uses GPU if available (`cuda`), otherwise defaults to `cpu`.\n",
        "\n",
        "3. **Initialize the YOLOv5 Model**:\n",
        "   - `yolo_model`: Instantiates the YOLOv5 model with the specified path and device. The model can then be used to perform object detection.\n",
        "\n",
        "4. **Open the Video File**:\n",
        "   - `cv2.VideoCapture('/content/5538137-hd_1920_1080_25fps.mp4')`: Loads the video file for processing. Replace the path with your desired video file if different.\n",
        "\n",
        "5. **Processing Each Frame**:\n",
        "   - `cap.isOpened()`: Checks if the video capture object is successfully opened.\n",
        "   - `cap.read()`: Reads each frame of the video one by one in a loop.\n",
        "   - `if not ret`: If `ret` is `False`, it means the video has ended or an error occurred, so the loop breaks.\n",
        "\n",
        "6. **Perform Object Detection**:\n",
        "   - `results = yolo_model.predict(frame)`: Uses the YOLO model to detect objects in the current frame. The `results` object contains information about detected objects, including bounding box coordinates, confidence scores, and class labels.\n",
        "\n",
        "7. **Draw Bounding Boxes and Labels**:\n",
        "   - `for *xyxy, conf, cls in results.pred[0]`: Loops through each detected object in the frame.\n",
        "     - `*xyxy`: Represents bounding box coordinates `(x1, y1, x2, y2)`.\n",
        "     - `conf`: Confidence score of the detected object.\n",
        "     - `cls`: Class index of the detected object.\n",
        "   - `label = results.names[int(cls)]`: Retrieves the class label name using `results.names`.\n",
        "   - `cv2.rectangle(...)`: Draws a bounding box around each detected object using coordinates `(x1, y1, x2, y2)`.\n",
        "   - `cv2.putText(...)`: Adds the class label and confidence score above each bounding box.\n",
        "\n",
        "8. **Display the Frame with Detections**:\n",
        "   - `cv2_imshow(frame)`: Displays the processed frame with bounding boxes and labels in Google Colab.\n",
        "\n",
        "9. **Exit Condition**:\n",
        "   - `cv2.waitKey(1) & 0xFF == ord('q')`: Checks for the 'q' key press to quit the loop.\n",
        "   - `cap.release()`: Releases the video capture object.\n",
        "   - `cv2.destroyAllWindows()`: Closes all OpenCV windows (mainly used outside of Colab)."
      ],
      "metadata": {
        "id": "BHLs7XiIRpiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIOw10K6RsY0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}